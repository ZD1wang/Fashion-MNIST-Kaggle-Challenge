{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion-MNIST Kaggle Challenge .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQoFNiVB1Ypu",
        "colab_type": "text"
      },
      "source": [
        "## Import statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK6eTSMh1Ugc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D, Dense, Flatten\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOFybqyY19Q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQOySpr32AtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!kaggle competitions download -c winter2020-mais-202"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTuFTK06zF2z",
        "colab_type": "text"
      },
      "source": [
        "## Load the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY3zDtPk2cny",
        "colab_type": "code",
        "outputId": "dd809eaa-5584-4d23-fbbe-0f89b0d4e677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!unzip winter2020-mais-202.zip\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  winter2020-mais-202.zip\n",
            "  inflating: label_int_to_str_mapping.csv  \n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test_images.npy         \n",
            "  inflating: train_images.npy        \n",
            "  inflating: train_labels.csv        \n",
            "label_int_to_str_mapping.csv  test_images.npy\twinter2020-mais-202.zip\n",
            "sample_data\t\t      train_images.npy\n",
            "sample_submission.csv\t      train_labels.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riBoBzzQ9xI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = np.load(\"train_images.npy\")\n",
        "test_images = np.load(\"test_images.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYJzIGHt-QZr",
        "colab_type": "text"
      },
      "source": [
        "# visualize an image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQPFRJiU-E2x",
        "colab_type": "code",
        "outputId": "7fcdf843-a570-45dd-dda2-4d583f8e65c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_image(arr):\n",
        "    two_d = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)\n",
        "    plt.imshow(two_d, interpolation='nearest')\n",
        "    plt.show()\n",
        "\n",
        "show_image(train_images[0]) # 0 is the index of the training image you want to display"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfjGYQRO-f7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = np.array((pd.read_csv(\"train_labels.csv\", index_col = 'ID')) ).astype(int)\n",
        "\n",
        "#flatten the images\n",
        "data1=[]\n",
        "data2=[]\n",
        "for img in train_images:\n",
        "  image_flatten=img.flatten()\n",
        "  np.reshape(image_flatten, (28, 28))\n",
        "  data1.append(image_flatten)\n",
        "for img in test_images:\n",
        "  image_flatten=img.flatten()\n",
        "  np.reshape(image_flatten, (28, 28))\n",
        "  data2.append(image_flatten)\n",
        "#scale the pixel to range [0,1]\n",
        "train_images = np.array(data1, dtype=\"float\") /255\n",
        "test_images = np.array(data2, dtype=\"float\") /255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFmfJwQP3_Nt",
        "colab_type": "code",
        "outputId": "354f51a6-067c-4104-dfa4-1c84263cbbb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(train_labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784)\n",
            "(50000, 1)\n",
            "[6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCFDo40xAcVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#img_rows, img_cols = 28, 28\n",
        "#input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUScRdRIC3W2",
        "colab_type": "code",
        "outputId": "3c7d942c-b6f6-4929-d511-9912311547df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# get a validation set\n",
        "size = int (len(train_images) *0.2)\n",
        "print(size)\n",
        "train_images = train_images[:-size]\n",
        "train_labels = train_labels[:-size].squeeze()\n",
        "valid_images = train_images[-size:]\n",
        "valid_labels = train_labels[-size:].squeeze()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz1g8bzo3hd5",
        "colab_type": "code",
        "outputId": "c8273380-ae4b-45a7-a374-9e56e0059088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(train_labels.shape)\n",
        "print(train_images.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000,)\n",
            "(40000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm21wD6GQg0K",
        "colab_type": "code",
        "outputId": "dd05f4fe-b860-4082-fefe-123dae533355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#lb = preprocessing.LabelBinarizer()\n",
        "#train_labels = lb.fit_transform(train_labels)\n",
        "#valid_labels = lb.transform(valid_labels)\n",
        "#print(train_labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZtPikSiYVNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "x = Input(shape=(28,28))\n",
        "\n",
        "#Encoder\n",
        "h = Dense(hidden_size, activation='relu', activity_regularizer=regularizers.l1(10e-5))(x)\n",
        "\n",
        "# Decoder\n",
        "r = Dense(output_size, activation='sigmoid')(h)\n",
        "\n",
        "autoencoder = Model(input=x, output=r)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSqxYhenaAGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_images, valid_images = train_images.reshape(-1, 28 * 28), valid_images.reshape(-1, 28 * 28)\n",
        "\n",
        "train_images, valid_images = train_images.reshape((-1, 28, 28, 1)), valid_images.reshape((-1, 28, 28, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy3_KKjb0EzO",
        "colab_type": "text"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTXdSyF6gfPB",
        "colab_type": "code",
        "outputId": "3f7a8f26-a153-40c1-e26e-f065da4f79f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "'''\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "inChannel = 1\n",
        "x, y = 28, 28\n",
        "input_img = Input(shape = (x, y, inChannel))\n",
        "\n",
        "def autoencoder(input_img):\n",
        "    #encoder\n",
        "    #input = 28 x 28 x 1 (wide and thin)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
        "\n",
        "    #decoder\n",
        "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 128\n",
        "    up1 = UpSampling2D((2,2))(conv4) # 14 x 14 x 128\n",
        "    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 64\n",
        "    up2 = UpSampling2D((2,2))(conv5) # 28 x 28 x 64\n",
        "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n",
        "    return decoded\n",
        "\n",
        "autoencoder = Model(input_img, autoencoder(input_img))\n",
        "autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())\n",
        "autoencoder.summary()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 7, 7, 128)         147584    \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 14, 14, 64)        73792     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 28, 28, 1)         577       \n",
            "=================================================================\n",
            "Total params: 314,625\n",
            "Trainable params: 314,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHtqHAxihOez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#autoencoder_train = autoencoder.fit(train_images, train_labels, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_images, valid_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeHPLUeS0WSp",
        "colab_type": "text"
      },
      "source": [
        "# Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkH2e0D8akGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "singleton_shape = (1, 28 * 28)\n",
        "encoding_dim = 8\n",
        "\n",
        "encoder = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(28 * 28,)),\n",
        "  tf.keras.layers.Dense(encoding_dim, activation=tf.nn.sigmoid),\n",
        "])\n",
        "\n",
        "decoder = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(encoding_dim, activation=tf.nn.sigmoid, input_shape=(encoding_dim,)),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(28 * 28, activation=tf.nn.sigmoid),\n",
        "])\n",
        "autoencoder = tf.keras.models.Sequential([encoder,decoder])\n",
        "\n",
        "autoencoder.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy')\n",
        "\n",
        "\n",
        "autoencoder.fit(train_images, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yn2JVgt0exO",
        "colab_type": "text"
      },
      "source": [
        "# Model 3 - The Real one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9D-eTg-0hdB",
        "colab_type": "code",
        "outputId": "b75aa5a0-6abf-47a7-8626-8b2c2c09982f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model = Sequential([\n",
        "  Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)),\n",
        "  Conv2D(32, kernel_size=3, activation='relu'),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=10,validation_data=(valid_images, valid_labels))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "40000/40000 [==============================] - 127s 3ms/step - loss: 0.6160 - acc: 0.7788 - val_loss: 0.4479 - val_acc: 0.8347\n",
            "Epoch 2/10\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.4371 - acc: 0.8428 - val_loss: 0.3903 - val_acc: 0.8567\n",
            "Epoch 3/10\n",
            "40000/40000 [==============================] - 128s 3ms/step - loss: 0.3828 - acc: 0.8604 - val_loss: 0.3203 - val_acc: 0.8854\n",
            "Epoch 4/10\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.3425 - acc: 0.8738 - val_loss: 0.2771 - val_acc: 0.9013\n",
            "Epoch 5/10\n",
            "40000/40000 [==============================] - 130s 3ms/step - loss: 0.3045 - acc: 0.8888 - val_loss: 0.2413 - val_acc: 0.9140\n",
            "Epoch 6/10\n",
            "40000/40000 [==============================] - 128s 3ms/step - loss: 0.2682 - acc: 0.9013 - val_loss: 0.2408 - val_acc: 0.9133\n",
            "Epoch 7/10\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 0.2326 - acc: 0.9149 - val_loss: 0.1873 - val_acc: 0.9330\n",
            "Epoch 8/10\n",
            "40000/40000 [==============================] - 128s 3ms/step - loss: 0.2021 - acc: 0.9245 - val_loss: 0.1533 - val_acc: 0.9462\n",
            "Epoch 9/10\n",
            "40000/40000 [==============================] - 128s 3ms/step - loss: 0.1714 - acc: 0.9365 - val_loss: 0.1298 - val_acc: 0.9528\n",
            "Epoch 10/10\n",
            "40000/40000 [==============================] - 126s 3ms/step - loss: 0.1462 - acc: 0.9466 - val_loss: 0.1150 - val_acc: 0.9597\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff6f38b62e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV7N59TP9BjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.evaluate(valid_images, valid_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkxfKaaoapTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test_images = np.load('test_images.npy').squeeze()\n",
        "#test_images = test_images.reshape(len(test_images), -1)\n",
        "test_images=test_images.reshape((-1, 28, 28, 1))\n",
        "y_test = model.predict_classes(test_images)\n",
        "\n",
        "df_test = pd.read_csv('sample_submission.csv')\n",
        "df_test['label'] = y_test\n",
        "df_test.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}